\documentclass[parskip=full]{scrartcl}

\pdfoutput=1

\title{Synthetic data generation: A literature review}

\author{%
	Joao Fonseca\(^{1*}\), Fernando Bacao\(^{1}\)
	\\
	\small{\(^{1}\)NOVA Information Management School, Universidade Nova de Lisboa}
	\\
	\small{*Corresponding Author}
	\\
	\\
	\small{Postal Address: NOVA Information Management School, Campus de
    Campolide, 1070--312 Lisboa, Portugal}
	\\
	\small{Telephone: +351 21 382 8610}
}

\usepackage{float}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{%
	a4paper,
	left=18mm,
	right=18mm,
	top=18mm,
}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{booktabs}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.14}
\usepackage{longtable}
\usepackage{tabu}
\usepackage{hyperref}
\usepackage{lineno}
\date{}


% use \citet for inline text references, \cite for normal citations
\usepackage[
    style=numeric,
    citestyle=numeric,
    sorting=none,
    natbib=true,
    backend=biber, 
    maxcitenames=1, 
    maxbibnames=99
]{biblatex}
\bibliography{references}
\usepackage{breakcites}

% Fix underfull hbox warnings in bilbliography
% Reference: https://tex.stackexchange.com/questions/10924/underfull-hbox-in-bibliography
\usepackage{etoolbox}
\apptocmd{\sloppy}{%
    \hbadness%
    10000\relax
}{}{}

% Fix overfull hbox warnings in bibliography
% Reference: https://tex.stackexchange.com/questions/171999/overfull-hbox-in-biblatex
\usepackage[T1]{fontenc}
\usepackage[final]{microtype}

% Highlight text: \hl
\usepackage{soul}

\definecolor{hypecol}{HTML}{0875b7}
\hypersetup{%
    colorlinks,
    linkcolor={hypecol},
    citecolor={hypecol},
    urlcolor={hypecol}
}

% Case-dependent packages here
\usepackage{tabularx}
\renewcommand\tabularxcolumn[1]{m{#1}}% for vertical centering text in X column

\begin{document}

\maketitle
\linenumbers

\begin{abstract}

    The generation of synthetic data can be used for anonymization,
    regularization, oversampling, semi-supervised learning, self-supervised
    learning and various other tasks. The wide range of applications of these
    mechanisms motivated the development of new algorithms specialized in
    generating data for specific types of data and Machine Learning (ML)
    tasks. As a result, the analysis of the different types of generative
    models 

    % We provide a broad taxonomy to define data generation mechanisms

    % We provide an analysis on recommendations for the evaluation of the
    % quality of the synthetic data generated

\end{abstract}

\section{Introduction}~\label{sec:introduction}

Synthetic data is obtained from a generative process based on properties of
real data~\cite{assefa2020generating}. The generation of synthetic data is
essential for various domains and tasks. For example, synthetic data is used
as a form of regularizing neural networks (\textit{i.e.}, data augmentation)
\textbf{[CITATION]}. One form of anonymizing datasets is via the production of
synthetic observations (\textit{i.e.}, synthetic data generation)
\textbf{[CITATION]}. In settings where only a small portion of training data
is labeled, some techniques generate artificial data using both labeled and
unlabeled data with a modified loss function to train neural networks
(\textit{i.e.}, semi-supervised learning)~\cite{laine2017temporal}. In
imbalanced learning contexts, synthetic data can be used to balance the target
classes' frequencies and reinforce the learning of minority classes
(\textit{i.e.}, oversampling)~\cite{fonseca2021improving}. Some active
learning frameworks use data generation to improve the quality of data
selection and classifier training~\cite{kim2021lada}. Other techniques employ
data generation to produce deep neural networks without labeled data
(\textit{i.e.}, self-supervised learning)~\cite{grill2020bootstrap}.

The breadth of these techniques span multiple domains, such as facial
recognition~\cite{lv2017data}, Land Use/Land Cover mapping
\textbf{[CITATION]}, medical image processing \textbf{[CITATION]}, Natural
Language Processing (NLP)~\cite{feng2021survey} or credit card default
prediction~\cite{alam2020investigation}. According to the domain and data
type, the data generation techniques used may vary significantly. Generally
speaking, some data generation mechanisms are specific to some domains, data
types or tasks. \hl{For example, \ldots}. Most, if not all, of these
techniques are applied on the input or output space.

However, there are various data generation techniques that are invariant to
the task or data types used. These techniques can be either applied in the
feature space~\cite{devries2017dataset} or in problems using tabular data. On
the one hand, data generation in the feature space uses a generative model to
learn a manifold, lower-dimensional abstraction over the input
space~\cite{kingma2019introduction}, defined here as the feature space. At
this level, any tabular data generation mechanism can be applied and
reconstructed into the input space if necessary. On the other hand, synthetic
data generation on tabular data can be applied to most problems. Although, the
choice of the generation mechanism is still dependant on (1) the importance of
the relationships found between the different features, (2) the ML task to be
developed and (3) the motivation for the generation of synthetic data. For
example, when generating data to address an imbalanced learning problem
(\textit{i.e.}, oversampling), the relationships between the different
features are not necessarily kept since the goal is to reinforce the learning
of the minority class by redefining an ML classifier's decision boundaries. If
the goal is to anonymize a dataset, perform some type of descriptive task, or
ensure a consistent model interpretability, these relationships need to be
kept.

Depending on the context, evaluating the quality of the generated data is a
complex task. For example, for image and time series data, perceptually small
changes in the original data can lead to large changes in the euclidean
distance~\cite{assefa2020generating, theis2016note}. The evaluation of
generative models typically account primarily for the performance in a
specific task, since good performance in one criterion does not imply good
performance on another~\cite{theis2016note}. However, in computationally
intensive tasks it is often impracticable to search for the optimal
configurations of generative models. To address this limitation, other
evaluation methods have been proposed to assist in this evaluation, which can
be distinguished into statistical divergence metrics and precision/recall
metrics~\cite{alaa2022faithful}. The relevant performance metrics found in the
literature are discussed in Section~\ref{sec:evaluating-synthetic-data}.

% Discuss Generative models -> Network based models

\subsection{Motivation and Contributions}

This literature review focuses on the generation mechanisms and generative
models underlying the different techniques where synthetic data is generated.
Specifically, we focus on techniques used in studies published since 2019. We
focus on the ML perspective of synthetic data, as opposed to the practical
perspective. From a practical sense, synthetic data is used as a proxy of real
data. It is assumed to be inaccessible, essential and a secondary asset for
tasks like education, software development, or systems
demonstrations~\cite{mannino2019real}. 

We focus on data generation techniques in the tabular and feature space
(\textit{i.e.}, embedded inputs), given its breadth in scope. Related
literature reviews are mostly focused on specific algorithmic or domain
applications, with little to no emphasis on the core generative process. For
this reason, these techniques often appear ``sandboxed'', even though there is
a significant overlap between them. There are some related reviews published
since 2019. \citet{assefa2020generating} provides a general overview of
synthetic data generation for time series data anonymization in the finance
sector. \citet{hernandez2022synthetic} reviews data generation techniques for
tabular health records anonymization. \citet{raghunathan2021synthetic} reviews
synthetic data anonymization techniques that preserve the statistical
properties of a dataset. \citet{nalepa2019data} reviews data augmentation
techniques for brain-tumor segmentation. \citet{bayer2021survey} distinguishes
augmentation techniques for text classification into feature and data space,
while providing an extensive overview of augmentation methods within this
domain. However, the taxonomy proposed and feature space augmentation methods
are not necessarily specific to the domain. \citet{shorten2021text},
\citet{chen2021empirical}, \citet{feng2021survey} and \citet{liu2020survey}
also review data augmentation techniques for text data.
\citet{yi2019generative} review Generative Adversarial Network architectures
for medical imaging. \citet{wang2020survey} reviews face data augmentation
techniques. \citet{shorten2019survey} and \citet{khosla2020enhancing} discuss
techniques for image data augmentation. \citet{iwana2021empirical} and
\citet{wen2020time} also review time series data augmentation techniques.
\citet{zhao2022graph} review data augmentation techniques for graph data. The
analysis of related literature reviews~\footnote{%
    Results obtained using Google Scholar, limited to articles published since
    2019, using the search query {\fontfamily{qcr}\selectfont (``synthetic
    data generation'' OR ``oversampling'' OR ``imbalanced learning'' OR ``data
    augmentation'') AND (``literature review'' OR ``survey'')}. Retrieved on
    August $11^{th}$, 2022. More articles were added later whenever found
    relevant.
} is shown in Table~\ref{tab:literature-reviews}.

% TODO: move table to appendix (?)
\begin{table}[t!]
    \centering
    \caption{\label{tab:literature-reviews}
        Related literature reviews published since 2019.
    }
    \small{
    \begin{tabularx}{\textwidth}{@{}rcccX@{}}
        \toprule
        Reference & Data type & ML problem & Domain & Observations \\
        \midrule

        \citet{assefa2020generating} & --- & Differential privacy &
        Finance & Analysis of applications, motivation and properties of
        synthetic data for anonymization. \\

        \citet{hernandez2022synthetic} & Tabular & Differential privacy &
        Healthcare & Focus on GANs. \\

        \citet{raghunathan2021synthetic} & Tabular & Differential privacy &
        Statistics & Focus on general definitions such as differential privacy
        and statistical disclosure control.\\

        \citet{nalepa2019data} & Image & Segmentation & Medicine & Analysis of
        algorithmic applications on a 2018 brain-tumor segmentation
        challenge.\\

        \citet{bayer2021survey} & Text & Classification & --- & Distinguish
        100 methods into 12 groups. \\

        \citet{shorten2021text} & Text & Deep Learning & --- & General
        overview of text data augmentation. \\

        \citet{chen2021empirical} & Text & Few-shot Learning & --- &
        Augmentation techniques for machine learning with limited data\\

        \citet{feng2021survey} & Text & --- & --- & Overview of augmentation
        techniques and applications on NLP tasks.\\

        \citet{liu2020survey} & Text & --- & Various & Analysis of industry
        use cases of data augmentation in NLP\@. Emphasis on input level data
        augmentation.\\

        \citet{yi2019generative} & Image & --- & Medicine & Emphasis on GANs.\\

        \citet{wang2020survey} & Image & Deep Learning & --- & Regularization
        techniques using facial image data. Emphasis on Deep Learning
        generative models.\\

        \citet{shorten2019survey} & Image & Deep Learning & --- & Emphasis on
        data augmentation as a regularization technique.\\

        \citet{khosla2020enhancing} & Image & --- & --- & Broad overview of
        image data augmentation. Emphasis on traditional approaches. \\

        \citet{iwana2021empirical} & Time series & Classification & --- &
        Defined a taxonomy for time series data augmentation.\\

        \citet{wen2020time} & Time series & Various & --- & Analysis of data
        augmentation methods for classification, anomaly detection and
        forecasting.\\

        \citet{zhao2022graph} & Graph & Various & --- & Graph data
        augmentation for supervised and self-supervised learning.\\

        \citet{khalifa2021comprehensive} & Image & --- & Various & General
        overview of image data augmentation and relevant domains of
        application.\\

        \bottomrule
        
    \end{tabularx}
    }
\end{table}


The different taxonomies established in the literature follow a similar
philosophy, but vary in terminology and are often specific to the technique
discussed. Regardless, it is possible to establish a broader taxonomy without
giving up on specificity. This study provides a joint overview of the
different data generation approaches, domains and ML techniques where data
generation is being used, as well as a common taxonomy across domains. It
extends the analyses found in these articles and uses the compiled knowledge
to identify research gaps. We compare the strengths and weaknesses of the
models developed within each of these fields. Finally, we identify possible
future research directions to address some of the limitations found. The
contributions of this paper are summarized below:

\begin{itemize}
    \item Bridge different ML concepts using synthetic data generation in its
        core \hl{(Algorithmic applications + Review of the State-of-the-art)}.
    \item Propose a synthetic data generation/data augmentation taxonomy to
        resolve the ambiguity in the literature \hl{(Data augmentation
        taxonomy)}.
    \item Characterize all relevant data generation methods using the proposed
        taxonomy. 
    \item Discuss the ML techniques in which synthetic data generation/data
        augmentation is used, beyond regularization and consolidate the
        current data generation mechanisms across the different techniques
        \hl{(Algorithmic Applications)}.
    \item Bring to light the key challenges of synthetic data generation and
        put forward possible research directions in the future.
\end{itemize}

% TODO: Develop research questions

\subsection{Paper Organization}

This paper is organized as follows: Section~\ref{sec:background} defines and
formalizes the different concepts, goals, trade-offs and motivations related
to synthetic data generation. Section~\ref{sec:taxonomy} establishes the
taxonomy used to categorize all the methods described in the paper.
Section~\ref{sec:feature-space} reviews synthetic data generation
mechanisms in the feature space. Section~\ref{sec:input-space}
reviews synthetic data generation mechanisms in the input space.
Section~\ref{sec:algorithmic-applications} describes the applications of
synthetic data in ML methods. Section~\ref{sec:evaluating-synthetic-data}
reviews performance evaluation methods of synthetic data generation
mechanisms. Section~\ref{sec:discussion} summarizes the main findings and
discusses limitations and possible research directions in the
state-of-the-art. Section~\ref{sec:conclusions} presents the main conclusions
drawn from this study.

\section{Background}~\label{sec:background}

% Definition
In this section we define basics concepts, common goals, trade-offs and
motivations regarding the generation of synthetic data in ML\@. We define
synthetic data generation as the production of observations using a generative
model (regardless of its nature) that resemble naturally occurring
observations within a certain domain. It requires access to either a training
dataset, a generative process, or a data stream. However, additional
requirements might be imposed depending on the ML task being developed. For
example, to generate artificial data for regularization purposes in supervised
learning (\textit{i.e.}, data augmentation) the training dataset must be
annotated \textbf{[CITATION]}. The generation of synthetic data for
anonymization purposes assumes synthetic datasets to be different from the
original data, while following the same statistical properties
\textbf{[CITATION]}. Domain knowledge may also be necessary to encode specific
relationships among features into the generative process.


\subsection{Use Cases}

%% Anonymize datasets (differential privacy)
The breach of sensitive information is an important barrier to the sharing of
datasets, especially when it concerns personal
information~\cite{dankar2021fake}. A common solution for this problem is the
generation of synthetic data without identifiable information. Generally
speaking, ML tasks that require data with sensitive information are not
compromised when using synthetic data.  The experiment conducted by
\citet{patki2016synthetic} using relational datasets showed that in 11 out 15
comparisons ($\approx 73\%$), practitioners performing predictive modelling
tasks using fully synthetic datasets performed the same or better than those
using the original dataset. This topic is discussed in
Section~\ref{sec:data-privacy}.

%% Generalization/regularization
A common problem in the training of deep neural networks are their capacity to
generalize~\cite{Zhang2021} (\textit{i.e.}, reduce the difference in
classification performance between known and unseen observations). Data
augmentation is a common method to address this problem. The generation of
synthetic observations increases the range of the possible input space used in
the training phase, which reduces the performance difference between known and
unseen observations. Although other regularization methods exist, data
augmentation is a useful method since it does not affect the choice in the
architecture of the ML classifier and does not exclude the usage of other
regularization methods. In domains such as computer vision and NLP, data
augmentation is also used to improve the robustness of models against
adversarial attacks~\cite{zeng2020data, morris2020textattack}. These topics
are discussed into higher detail in Section~\ref{sec:regularization}.

%% Oversampling
In supervised learning, synthetic data generation is often motivated by the
need to balance target class distributions (\textit{i.e.}, oversampling).
Since most ML classifiers are designed to perform best with balanced datasets,
defining an appropriate decision boundary to distinguish rare classes becomes
difficult~\cite{saez2016analyzing}. Although there are other approaches to
address imbalanced learning, oversampling techniques are generally easier to
implement since they do not involve modifications to the classifier. This
topic is discussed into higher detail in Section~\ref{sec:oversampling}.

%% Active Learning + Few-shot Learning
In supervised learning projects where labeled data is not readily available,
but can be labeled, an Active Learning (AL) method may be used to improve the
labelling process. AL aims to reduce the cost of producing training datasets
by finding the most informative observations to label and feed into the
classifier~\cite{fonseca2021increasing}. In this case, the generation of
synthetic data is particularly useful to reduce the amount of labelled data
required for a successful ML project and its costs. A similar motivation
applies to the case of few-shot learning: small datasets may be expanded with
synthetic data~\cite{kumar2019closer}. These topics are discussed in
Sections~\ref{sec:active-learning} and~\ref{sec:few-shot-learning}.

%% Semi-supervised Learning + Self-supervised learning
The two other techniques reliant on synthetic data generation is both
Semi-supervised and Self-supervised learning. The former leverages both
labeled and unlabeled data in the training phase, simultaneously. Most of the
methods in the literature apply perturbations on the training data as part of
the training procedure~\cite{van2020survey}. Self-supervised learning is a
technique used to train neural networks in the absence of labeled data. Both
techniques use synthetic data generation as an internal procedure for most of
these methods. These techniques are discussed in
Sections~\ref{sec:semi-supervised-learning}
and~\ref{sec:self-supervised-learning}.


% Concepts definition, goals + trade-offs, Motivations

% Concepts definition
% - Original dataset
% - Synthetic dataset
% - Generator
% - Quality criteria (e.g., similarity function)
% - Objective performance metric (ML method to improve)
 
% Common success criteria 
% - The synthetic dataset should be different than the original dataset (i.e.,
%   no duplicates)
% - It should minimize a similarity function
% - The statistical properties of the dataset are preserved
% - It should improve the output of the objective performance
 
% Trade-offs
% - Additional computational overhead
% - Expose the classifier to unfeasible input areas
% 

\subsection{Problem Formulation}~\label{sec:problem-formulation}

Original dataset, $\mathcal{D}$, which can be distinguished according to
whether a target feature exists, $\mathcal{D}_L = {((x_i, y_i))}^l_{i=1}$, or
not, $\mathcal{D}_U = {(x_i)}^{u}_{i=1}$. All three datasets, $\mathcal{D}$,
$\mathcal{D}^L$ and $\mathcal{D}^U$ consist of ordered collections with
lengths $l+u$, $l$ and $u$, respectively. Synthetic data generation is
performed using a generator, $f_{gen}(x;\tau) = \tilde{x}$, where $\tau$
defines the generation policy (\textit{i.e.}, type of transformation and its
hyperparameters), $x \in \mathcal{D}$ is an observation and $\tilde{x} \in
\mathcal{D}^S$ is a synthetic observation. Analogous to $\mathcal{D}$, the
synthetic dataset, $\mathcal{D}^S$, is also distinguished according to whether
there is an assignment of a target feature, $\mathcal{D}^S_L = {((\tilde{x}_i,
\tilde{y}_i))}^{l'}_{i=1}$, or not, $\mathcal{D}^S_U =
{(\tilde{x}_i)}^{u'}_{i=1}$.

% - Quality criteria (e.g., similarity function)
Depending on the ML task, it may be relevant to establish metrics to measure
the quality of $\mathcal{D}^S$. In this case, a metric
$f_{qual}(\mathcal{D}^s, \mathcal{D})$ is used to determine the level of
similarity/dissimilarity

% - Objective performance metric (ML method to improve)

\section{Data Generation Taxonomy}~\label{sec:taxonomy}

Image data augmentation taxonomy~\cite{khalifa2021comprehensive}

There is a distinction between semantic and traditional image data
augmentation~\cite{wang2021regularizing}, also discussed
in~\cite{shorten2019survey} 

Synthetic data generation for medical records
taxonomy~\cite{hernandez2022synthetic} which is incomplete



Data generation mechanisms can be characterized in 4 properties: Architecture,
Application level, Scope and Data space. The overall definition of the
proposed taxonomy is shown in Figure~\ref{fig:data-generation-taxonomy}.

\begin{enumerate}
    \item Level of application (External or Internal)
    \item Scope (Local or Global augmentation)
    \item Architectural approach (heuristic, network-based or others)
    \item Data space (Input, feature or output). Within feature and output: Domain
\end{enumerate}

\begin{figure}
	\centering
	\includegraphics[width=.8\linewidth]{../analysis/data-generation-taxonomy}
    \caption{General taxonomy of data generation mechanisms proposed in this
        paper.
    }~\label{fig:data-generation-taxonomy}
\end{figure}


\section{Data Generation in the Feature Space}~\label{sec:feature-space}
% Feature level data augmentation

The concept of data generation in the feature space was popularized
with~\cite{devries2017dataset}.

According to~\cite{assefa2020generating}. The generation of synthetic data
should aim to fulfil the conditions below:

\begin{itemize}
    \item Privacy preserving.
    \item Human readable.
    \item Compact.
\end{itemize}

Discuss Auto-augmentation (as mentioned in~\cite{wang2020survey}) or meta
learning (as mentioned in~\cite{shorten2019survey})

\section{Data Generation in the Input Space}~\label{sec:input-space}
% Review of the State-of-the-art of domain specific data generation

In this section, we describe some popular domain and data type-specific data
generation techniques. For each data type we include a table with related
literature reviews specific to different domains.

\subsection{Tabular}
% TODO: 
% - Table with literature review references 

\subsection{Time series}
% TODO: 
% - Table with literature review references 

Generative adversarial networks in time series 

\subsection{Image}
% TODO: 
% - Table with literature review references 

Image-specific data generation mechanisms can be further divided into
traditional and semantic techniques~\cite{wang2021regularizing}. Traditional
generation techniques comprise simple modifications such as translation,
cropping or random erasing~\cite{zhong2017random}. Semantic generation methods
involve more complex tasks, such changing colors of specific attributes,
backgrounds and visual angles \textbf{[CITATION]}. 
% Go back to explaining wang2021regularizing

% semantic generation technique
Data generation by modifying specific attributes in data points with known
perturbations~\cite{lv2017data}. For example, overlaying facial elements into
a picture containing a human face (\textit{e.g.}, adding sunglasses and
different hairstyles), introducing perturbations in facial landmarks,
different illumination and artificial misalignment are different approaches to
generate artificial observations for facial recognition.

% GANs
Generative Adversarial Networks in computer vision~\cite{wang2021generative}

% traditional
% - mixup

\subsection{Text}
% TODO: 
% - Table with literature review references 

NLP motivations~\cite{feng2021survey}:

\begin{enumerate}
    \item Low-resource languages (NLP)
    \item Mitigate bias
    \item Fixing class imbalance
    \item Few-shot learning
    \item Adversarial examples
\end{enumerate}


NLP also benefit from data augmentation~\cite{feng2021survey}.

In NLP, there is the challenge of establishing universal rules for text
transformations to provide new linguistic patterns~\cite{bayer2022data}

https://github.com/styfeng/DataAug4NLP

\subsection{Graphs}


Another relevant paper~\cite{zhou2020data}

Various graph data augmentation methods can be applied to related data types
such as text data~\cite{shorten2021text}.


An analysis on different graph data augmentation techniques and a new graph
data augmentation framework~\citet{zhao2021data}

List of papers about graph data augmentation:
https://github.com/zhao-tong/graph-data-augmentation-papers

\subsection{Audio}

\section{Algorithmic applications}~\label{sec:algorithmic-applications}

\subsection{Data Privacy}~\label{sec:data-privacy}

SynSys~\cite{dahmen2019synsys}, Sensegen~\cite{alzantot2017sensegen}, The
Synthetic Data Vault~\cite{patki2016synthetic}

% Introduce synthetic data generation
Synthetic data generation is a technique used to produce synthetic, anonymized
versions of datasets~\cite{dankar2021fake}. It is considered a good approach
to share sensitive data without compromising significantly a given data mining
task~\cite{taub2018differential, park2018data}. Traditional data anonymization
techniques, as well as federated learning are two other viable solutions for
privacy-preserving data publishing tasks, but contain
drawbacks~\cite{hernandez2022synthetic}. On the one hand, traditional data
anonymization requires domain knowledge, is labor intensive and remains
susceptible to disclosure~\cite{reiter2004new}. On the other hand, federated
learning is a technically complex task that consists on training ML
classifiers on edge devices and aggregating temporarily updated parameters on
a centralized server, instead of aggregating the training
data~\cite{yu2022survey}. Although it prevents sharing sensitive data, its
applicability is dependent on the task. Dataset anonymization via synthetic
data generation attempts to balance disclosure risk and data utility in the
final synthetic dataset. The goal is to ensure observations are not
identifiable and the relevant data mining tasks are not
compromised~\cite{singh2017aggregating, li2018privacy}.

The generation of synthetic datasets allow a more flexible approach to the
successful implementation of ML tasks. However,

Anonymizing data using synthetic data generation in the financial
sector~\cite{assefa2020generating}.

Guidelines for effective synthetic data generation~\cite{dankar2021fake}





\subsection{Regularization in Supervised Learning}~\label{sec:regularization}

% Introduce data augmentation
The performance of Machine Learning models is highly dependent on the quality
of the training dataset used~\cite{Fenza2021, Halevy2009}. The presence of
imbalanced and/or small datasets, target labels incorrectly assigned, outliers
and high dimensional input spaces reduce the prospects of a successful machine
learning (ML) model implementation~\cite{Halevy2009, Domingos2012,
Salman2019}. In the case of deep learning, for example, these
models are often limited by a natural inclination to overfitting, label noise
memorization and catastrophic forgetting~\cite{Xie2021}. Regularization
methods are the typical approach to address these problems, but producing
robust ML solutions is still a challenge~\cite{Zhang2021}.

It is frequently assumed that the training data is sampled from a fixed data
source, it is balanced and does not contain label noise. Under these
conditions, the resulting ML classifier is expected to achieve good
generalization performance~\cite{benning2018modern}. Although, in practical
applications, this is rarely the case. When the training data is not
representative of the true population, or the model is over-parametrized, it
becomes particularly prone to overfitting~\cite{Bartlett2021}. Regularization
methods attempt to address these limitations. They can be divided into three
categories~\cite{santos2022avoiding}:

\begin{enumerate}
    \item Output level modifications. Transforms the labels in the training
        data.
    \item Algorithmic level modifications. Modifies the classifier's
        architecture, loss function or other components in the training
        procedure.
    \item Input level modifications. Modifies the training dataset by expanding it
        with synthetic data.
\end{enumerate}

The last approach, input level modifications, is known as data augmentation.
Data augmentation is used to increase the size and data variability of data in
a training dataset, by producing synthetic observations~\cite{Van2001,
Wong2016}. Since it is applied at the data level, it can be used for various
types of problems and classifiers~\cite{Behpour2019}. 

Problems such as fraud detection and healthcare are frequently tackled via
synthetic data generation~\cite{ekbatani2017synthetic}.

``Su et al. [78] show that 70.97\% of images can be misclassified by changing
just one pixel'' \citet{shorten2019survey}

``Moreover, the current research about so called adversarial attacks on CNNs
showed that deep neural networks can be easily fooled into misclassification
of images just by partial rotations and image translation [1], adding the
noise to images [5] and even changing one, skillfully selected pixel in the
image [6].'' \citet{mikolajczyk2018data}

Data augmentation can also be used to improve a model's robustness against
adversarial attacks. 

% NOTE: Using an ensemble of views of the same observation to the same
% classifier and checking the different predictions has surely been explored
% (?) 
% i.e., augmentation at inference time, instead of training

\subsection{Oversampling}~\label{sec:oversampling}

KernelADASYN~\cite{tang2015kerneladasyn}

The original author of SMOTE recently published the paper ``Efficient Augmentation for Imbalanced Deep
Learning''~\cite{dablain2022efficient}

\subsection{Active Learning}~\label{sec:active-learning}

\subsection{Few-shot Learning}~\label{sec:few-shot-learning}

Analysis of six feature space data augmentation techniques for few-shot
learning~\cite{kumar2019closer}

FlipDA~\cite{zhou2021flipda}

\subsection{Semi-supervised Learning}~\label{sec:semi-supervised-learning}

Synthetic data generation for semi-supervised learning given limited labeled
data regarding the COVID-19 pandemic~\cite{das2022conditional}.

Extensive literature review on semi-supervised learning~\cite{van2020survey}

\subsection{Self-supervised Learning}~\label{sec:self-supervised-learning}

\section{Evaluating the Quality of Synthetic Data
}~\label{sec:evaluating-synthetic-data}

The log-likelihood (and equivalently the Kullback-Leibler Divergence) is a
de-facto standard to train and evaluate generative
models~\cite{theis2016note}. Other common metrics include Parzen window
estimates, which~\citet{theis2016note} show that these metrics behave
independently and should generally be avoided. Therefore, it is necessary
to evaluate generative models with respect to the application these models are
being developed for.


The evaluation of generative models should quantify three key aspects of
synthetic data~\cite{alaa2022faithful}:

\begin{enumerate}
    \item Fidelity
    \item Diversity 
    \item Generalization
\end{enumerate}

The 3-dimensional metric proposed by~\citet{alaa2022faithful} quantifies these
aspects via the combination of three metrics ($\alpha$-Precision,
$\beta$-Recall and Authenticity) for various application domains.

\subsection{Statistical Divergence Metrics} 

\subsection{Precision/Recall Metrics}

\section{Discussion}~\label{sec:discussion}

\subsection{Main Findings}

The combination of data generation strategies is an approach commonly found in
different problems, such as self-supervised
learning~\cite{grill2020bootstrap}. It can be more frequently found in text
data applications~\cite{bayer2021survey} and image data \textbf{[CITATION]}.

\subsubsection{RQ1: bla bla bla}

\subsubsection{RQ2: bla bla bla}

\subsubsection{RQ3: bla bla bla}

\subsection{Limitations}

Research across the different applications appears to be sandboxed even though
all techniques integrate synthetic data in its core.

Given the breadth and complexity of input-level and feature-level data
generation mechanisms, it is increasingly important to find a method to
efficiently determine the most appropriate data generation policies. However,
the complexity of this task is determined by various factors: different data
types, ML problems, model architectures, computational resources, performance
metrics and contextual constraints. Auto-augmentation and meta learning aim to
address this challenge and are still subject to active research.

% Synthetic data generation with a real valued y?

% data privacy
The evaluation of anonymization techniques lack standardized, objective and
reliable performance metrics and benchmark datasets to allow an easier
comparison across classifiers to evaluate key aspects of data anonymization
(resemblance, utility, privacy and performance). These datasets should contain
mixed data types (\textit{i.e.}, a combination of categorical, ordinal,
continuous and discrete features) and the metrics should evaluate the
performance of different data mining tasks along with the anonymization
reliability. This problem appears to be universal across domains. For example,
\citet{hernandez2022synthetic} observed the lack of a universal method or metric
to report the performance synthetic data generation algorithms for tabular
health records.

Computational cost and inconsistent quality of synthetic data generated with
GANs (\textit{e.g.}, mode collapse).

% Regularization in supervised learning
Unlike with data privacy solutions, data augmentation techniques generally do
not consider the similarity/dissimilarity of synthetic data. The study of
quality metrics for supervised learning may reduce computational overhead and
experimentation time. No studies related to the relationship of quality
metrics and performance in the primary ML task were found
\textbf{[CONFIRM!!!]}.

There is not a clear understanding of what types of data augmentation methods
are more appropriate according to different model architectures, ML tasks or
domains and the reason why they work better or worse depending on the task. 
In addition, it is still unclear \textit{why} data augmentation works.
Research on this topic lacks depth and fails to address the theoretical
underpinnings~\cite{feng2021survey}.

``Dao et al. (2019) note that ``data augmentation is typically performed in an
ad-hoc manner with little understanding of the underlying theoretical
principles'', and claim the typical explanation of DA as regularization to be
insufficient.''~\cite{feng2021survey}

% oversampling
There is a lack of research on oversampling solutions to generate synthetic
data with mixed data types and datasets with exclusively non metric features.

There is a lack of methods adapted to use categorical features for tabular
data.

% Active Learning

% Semi-supervised Learning

% Self-supervised Learning
There is no clear understanding of the most appropriate data augmentation
techniques used to train self-supervised models and how their behavior and
performance varies according to the data generation method used.

% Societal challenges raised by data generation (?)
% Systematic bias

oversampling does not seem to be a relevant source of bias in behavioral
research and does not appear to have an appreciably different effect on
results for directly versus indirectly oversampled
variables~\cite{hauner2014latent}

% Maybe discuss adversarial attacks?

\subsection{Research directions}

% similarities between mixup and SMOTE, and an intermediate solution that can
% be further explored to use the mixup approach on tabular data
% (Geometric-SMOTE selection mechanism)

Quantifying the quality of the generated data:

\begin{enumerate}
    \item Realistic
    \item Similarity
    \item Usefulness (determine purpose and relevant performance metric)
    \item Understand the relationship between the 3 factors
\end{enumerate}

\section{Conclusions}~\label{sec:conclusions}

\printbibliography
\end{document}
